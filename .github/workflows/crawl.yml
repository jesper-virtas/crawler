name: batch-crawl-to-n8n

on:
  workflow_dispatch:
    inputs:
      sheet_url:
        description: "Google Sheet CSV (optional). If empty, uses secret SHEET_URL or urls.txt"
        required: false
      concurrency:
        description: "Parallel fetches"
        required: false
        default: "4"

concurrency:
  group: "batch-crawl"
  cancel-in-progress: true

jobs:
  run:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Install Playwright browser
        run: python -m playwright install chromium

      - name: Verify N8N webhook secret is present
        run: |
          if [ -n "${{ secrets.N8N_WEBHOOK_URL }}" ]; then
            echo "OK: N8N_WEBHOOK_URL secret is set"
          else
            echo "MISSING: N8N_WEBHOOK_URL secret" && exit 1
          fi

      - name: Resolve SHEET_URL
        run: |
          if [ -n "${{ inputs.sheet_url }}" ]; then
            echo "SHEET_URL=${{ inputs.sheet_url }}" >> $GITHUB_ENV
          elif [ -n "${{ secrets.SHEET_URL }}" ]; then
            echo "SHEET_URL=${{ secrets.SHEET_URL }}" >> $GITHUB_ENV
          else
            echo "No SHEET_URL provided (input/secret). Will use urls.txt."
          fi

      - name: Run batch crawl
        env:
          N8N_WEBHOOK_URL: ${{ secrets.N8N_WEBHOOK_URL }}
          SHEET_URL: ${{ env.SHEET_URL }}
          CONCURRENCY: ${{ inputs.concurrency }}
          URLS_FILE: urls.txt
          WAIT_MS: "6000"
          TIMEOUT: "45"
        run: |
          python fetch_crawl4ai.py
